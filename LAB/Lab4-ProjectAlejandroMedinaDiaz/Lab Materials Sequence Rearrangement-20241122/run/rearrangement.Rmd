---
title: "DNA Rearrangement: PrefixSort and Greedy Approaches"
author: "Alejandro Medina Diaz"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    latex_engine: xelatex
    fig_caption: yes
    toc: false
    extra_dependencies: ["placeins", "subfig"]
papersize: a4
fontsize: 11pt
geometry:
  - top=1in
  - bottom=1in
  - left=1.5in
  - right=1.5in
params:
  algorithms: ["PrefixSort", "BreakpointReversal"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

Context of the Project
This project focuses on sequence rearrangement algorithms, which aim to sort or rearrange permutations using minimal operations. These problems are crucial in areas like computational biology (e.g., genome rearrangement) and optimization. The study involves analyzing two algorithms that address these challenges with distinct approaches and objectives.

Breakpoint Reversal Algorithm
The Breakpoint Reversal Algorithm reduces breakpoints—positions where consecutive elements are not adjacent in value—by applying reversal operations between them. It identifies breakpoints, generates candidate reversals, and evaluates their quality based on how effectively they reduce the total number of breakpoints.

Prefix Sort Algorithm
The Prefix Sort Algorithm sorts permutations by iteratively applying prefix reversals, which reverse the first k elements of the sequence. It works by locating out-of-place elements, determining their current position, and performing a prefix reversal to move them to the correct spot, repeating this until the sequence is sorted.


# Experimental Setup

Experimental Setup
The experiments are designed to evaluate the performance of the Breakpoint Reversal Algorithm and the Prefix Sort Algorithm. The algorithms will be tested on various permutations of different lengths, assessing their efficiency in terms of the number of operations performed and the runtime required. The main parameters include the size of the permutations (ranging from small to large sequences) and the type of permutation (randomized or structured). The quality of the solutions will also be analyzed, particularly the reduction in breakpoints and the total reversals applied.

The experiments will be conducted in a controlled computational environment to ensure consistency and repeatability. All algorithms will be implemented in Java, and the results will be recorded for comparison. Measurements will include the number of operations performed, runtime (in milliseconds), and, for the Breakpoint Reversal Algorithm, the change in the number of breakpoints. (see Table \ref{tab:conf}).

\begin{table}[!h]
\caption{Computational environment considered.}
\begin{tabular}{lp{0.8\linewidth}}
\hline
CPU       & Intel Core i7-12700H, 16GB RAM \\
OS        & Windows 11 Pro, Version 22H2\\
Java      & Java OpenJDK 17.0.8\\
\hline
\end{tabular}
\label{tab:conf}
\end{table}


# Empirical Results

A summary of the experimental results is provided in Tables \ref{tab:PrefixSort} and \ref{tab:BreakpointReversal} in the Appendix, along with the statistical fitting of the data to different growth models. 

Describe the results, in particular Figure \@ref(fig:ops).

Figure 1 illustrates the normalized number of reversals (operations per sequence length) for both the Breakpoint Reversal and Prefix Sort algorithms as the permutation length increases. The y-axis represents the ratio of operations to sequence length, and the x-axis represents the permutation length, denoted by 
lambda. The data is fitted to growth models that highlight the convergence behavior of the algorithms as sequence length increases.

The Prefix Sort Algorithm, shown in red, exhibits slightly higher normalized operation counts compared to the Breakpoint Reversal Algorithm, shown in blue. Both algorithms demonstrate a decreasing rate of additional operations with increasing sequence length, approaching asymptotic limits. The statistical fits confirm this trend, with Prefix Sort following 
1−(1.31 K − 0.688)
1−(1.31 K − 0.688) 

and Breakpoint Reversal following (K for lambda)

1−(1.35 K  − 0.587)
1−(1.35 K − 0.587).

As sequence length grows, the operations required per element stabilize near 1 for both algorithms. However, the Prefix Sort curve approaches this limit more steeply, indicating its efficiency in normalizing the operation count for larger permutations. Breakpoint Reversal, while slower to converge, displays consistent behavior over longer sequences due to its heuristic-based approach to reducing breakpoints.

This comparison highlights the distinct optimization strategies of the two algorithms and their effectiveness as permutation length increases. While Prefix Sort is slightly more efficient in operation count per element, the Breakpoint Reversal Algorithm remains competitive, especially for intermediate sequence lengths.



```{r load-data}
load_data <- function  (filename) {
  # Reading the data
  rawdata = read.table(paste0(filename, "rearrangement.txt"))
  
  # Compute basic statistics 
  stderr <- function(x) sd(x)/sqrt(length(x))
  m <- dim(rawdata)[1];
  n <- dim(rawdata)[2];
  even_ind <- seq(2, n, 2)
  dataframe <- data.frame(
    "length" = rawdata[,1],
    "ops" = apply(t(rawdata)[even_ind,], 2, mean)/rawdata[,1],
    "opserr" = apply(t(rawdata)[even_ind,], 2, stderr)/rawdata[,1]
  )
  
  # Statistical model: 1 - power_law
  
  xx <- seq(min(rawdata[,1]), max(rawdata[,1]), by = .1)
  b0 <- log((1-dataframe$ops[m])/(1-dataframe$ops[m-1]))/log(dataframe$length[m]/dataframe$length[m-1])
  a0 <- (1-dataframe$ops[m])/(dataframe$length[m]^b0)
  datafit <- nls((1-ops) ~ a * length ^ b, data=dataframe, start = list(a = a0, b = b0))
  fitfun <- function(x) predict(datafit, newdata=data.frame(length=x))
  pwrdata <- data.frame(
    "length" = xx,
    "ops"  = 1-fitfun(xx)
  )
  
  datalist <-list(data = dataframe, fit = datafit, f = fitfun, predict = pwrdata)

}

algorithm_data <- list()
for (alg in params$algorithms) {
    algorithm_data[[alg]] <- load_data(alg)
}

```


```{r ops, fig.cap="Reversals (normalized per number of elements) for increasing sequence length", fig.align = "center"}

# Graphical representation

library(ggplot2)
library(scales)
library(ggnewscale)
library(latex2exp)


data <- data.frame(matrix(ncol=4, nrow=0))
colnames(data) = c("length", "ops", "opserr", "algorithm")
predict <- data.frame(matrix(ncol=3, nrow=0))
colnames(data) = c("length", "ops", "algorithm")

labs <- c()
for (alg in params$algorithms) {
  labpwr <- paste("$1 - \\left(",
                  format(summary(algorithm_data[[alg]]$fit)$coefficients[1], scientific=FALSE, digits=3),
                  "\\lambda^{",
                  format(summary(algorithm_data[[alg]]$fit)$coefficients[2], scientific=FALSE, digits=3),
                  "}\\right)$")
  labs <- c(labpwr, labs)
  tmp <- algorithm_data[[alg]]$data
  tmp$algorithm <- alg 
  data <- rbind(data, tmp)
  tmp <- algorithm_data[[alg]]$predict
  tmp$algorithm <- alg 
  predict <- rbind(predict, tmp)
}
labs <- lapply(labs, TeX)

figure <- ggplot(data = data, aes(x = length, y = ops, group = algorithm)) + 
    geom_line(data = predict, aes(x=length, y=ops, colour = algorithm)) +
    scale_colour_manual(name = "Statistical fit", values = c("blue", "red"), labels = labs) +
    new_scale_color() + 
    geom_errorbar(aes(ymin=ops-opserr, ymax=ops+opserr, colour = algorithm), width=.2) +
    geom_point(shape=21, size=3, fill="white",mapping = aes(colour = algorithm)) +
    scale_colour_manual(name = "Data", values = c("blue", "red")) +
    guides(color = guide_legend(override.aes = list(shape = c(1, 1), linetype = c("blank", "blank")))) +
    scale_y_continuous(name = "operations / length") +
    scale_x_continuous(name = TeX("permutation length $\\lambda$"))+
    theme_bw() + 
    theme(legend.justification = c(0, 1), 
        legend.position = "inside", 
        legend.position.inside = c(0.7, .5), 
        legend.box.margin=margin(c(5,5,5,5))) 

show(figure)

```



# Discussion

Provide your interpretation of the results: discuss whether the results match the theoretical predictions, whether some algorithm is better in practice than others, etc.

The results depicted in Figure 1 largely align with theoretical predictions for the Prefix Sort and Breakpoint Reversal algorithms. Both algorithms demonstrate asymptotic behavior, with their normalized operation counts converging toward a value near 1 as the permutation length increases. This indicates that both algorithms scale effectively for larger inputs, requiring roughly one operation per element to achieve their respective goals.

Comparison to Theoretical Predictions
The observed behavior is consistent with theoretical expectations:

Prefix Sort: The results reflect the algorithm's efficient sorting mechanism, where each element is positioned correctly in a bounded number of prefix reversals. The rapid convergence of the normalized operation count (as seen in the steeper curve) matches its theoretical efficiency, particularly for unsigned permutations.
Breakpoint Reversal: The algorithm performs more operations at shorter sequence lengths but converges more slowly to its asymptotic limit. This aligns with its heuristic nature, as it relies on finding and minimizing breakpoints incrementally, which may involve more operations in smaller or highly disordered permutations.
Practical Comparison
While both algorithms are effective, Prefix Sort appears to perform slightly better in practice:

Normalized Operation Count: Prefix Sort consistently requires fewer operations per element than Breakpoint Reversal across all sequence lengths, as shown by the red curve being above the blue curve.
Convergence: Prefix Sort converges faster to its theoretical limit, making it more efficient for large-scale problems.
Specialization: Breakpoint Reversal’s focus on reducing breakpoints makes it more suitable for applications where minimizing specific disorder metrics (like breakpoints) is critical, even if it requires additional operations.
General Insights
In practice, the choice of algorithm depends on the problem’s specific requirements:

Use Prefix Sort when the primary objective is sorting a sequence quickly and efficiently.
Opt for Breakpoint Reversal when the problem prioritizes breakpoint reduction, even at the cost of additional operations.
Overall, while Prefix Sort shows a slight edge in practical efficiency, both algorithms perform well and match their theoretical scaling, demonstrating their applicability in sequence rearrangement tasks.


\FloatBarrier

\setcounter{section}{0}
\renewcommand{\thesection}{\Alph{section}}

# Appendix

## Data Summary 

```{r data-summary}
library(knitr)
library(kableExtra)

create_table <- function (dataframe, algorithm) {
  table_dataframe <- data.frame(
    "length" = format(dataframe$length, scientific=FALSE, digits = 3),
    "ops" =    format(dataframe$ops, scientific=FALSE, digits = 3),
    "opserr" = format(dataframe$opserr, scientific=TRUE, digits = 3)
  )
  
  kable(table_dataframe, "pipe",
        longtable = TRUE,
        format = "latex",
        linesep = "",
        col.names = c("length $\\lambda$", "operations", "std. err."),
        escape = FALSE,
        align = "c",
        caption = paste0("Summary of the experimental results for ", algorithm, ". The mean and standard error are shown for each length.\\label{tab:", algorithm, "}")) %>%
    row_spec(0,bold=TRUE) %>%
    kable_styling(latex_options = c("striped", "hold_position"))
}

table <- list()
for (alg in params$algorithms) {
  table[[alg]] <- create_table(algorithm_data[[alg]]$data, alg)
}
```

```{r tables, results = 'asis'}
for (alg in params$algorithms) {
  show(table[[alg]])
}
```

## Model Fitting 

```{r model}
for (alg in params$algorithms) {
  cat (alg)
  show(summary(algorithm_data[[alg]]$fit))
}
```


  


